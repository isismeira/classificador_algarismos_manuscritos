# ‚úçüèΩ Classifica√ß√£o de algarismos escritos √† m√£o com SGDClassifier, SupportVectorClassifier, K-nearest-neighbors e RandomForests

## üéØ Objetivo

Este projeto tem como objetivo desenvolver e avaliar modelos de machine learning para classificar algarismos escritos √† m√£o utilizando o conjunto de dados MNIST. O foco √© explorar diferentes abordagens de classifica√ß√£o, incluindo classifica√ß√£o bin√°ria, multiclasse, multirr√≥tulo e multioutput, e analisar o desempenho dos modelos utilizando m√©tricas como Valida√ß√£o Cruzada, Precis√£o, Revoca√ß√£o, F1 Score e ROC AUC.

## üíæ Dataset

O conjunto de dados utilizado √© o MNIST (Modified National Institute of Standards and Technology), que consiste em aproximadamente 70.000 imagens em tons de cinza de 28x28 pixels de d√≠gitos escritos √† m√£o por estudantes e funcion√°rios do US Census Bureau. Cada imagem representa um d√≠gito de 0 a 9. O dataset j√° vem pr√©-dividido em 60.000 imagens para treinamento e 10.000 para teste.

## üîéAn√°lise Explorat√≥ria de Dados (EDA)

Foi realizada uma an√°lise inicial do dataset para entender sua estrutura e visualizar exemplos dos d√≠gitos escritos √† m√£o. Cada imagem √© representada por um vetor de 784 caracter√≠sticas, correspondendo √† intensidade de cada pixel.

## ‚úåüèΩ Classifica√ß√£o Bin√°ria

Inicialmente, foi abordado o problema como uma classifica√ß√£o bin√°ria, focando em identificar se uma imagem representava o d√≠gito '5' ou n√£o. Para isso, foi utilizado o classificador Gradiente Descendente Estoc√°stico (SGDClassifier), conhecido por sua efici√™ncia com grandes datasets.

O desempenho do classificador bin√°rio foi avaliado utilizando valida√ß√£o cruzada k-fold. Observou-se que a acur√°cia, por si s√≥, pode ser enganosa em datasets assim√©tricos como o MNIST (onde a classe '5' representa apenas cerca de 10% dos dados).

Para uma avalia√ß√£o mais detalhada, foram utilizadas a matriz de confus√£o, precis√£o, revoca√ß√£o (recall) e o F1-score. A an√°lise revelou que o classificador obteve uma precis√£o razo√°vel, mas com uma revoca√ß√£o menor, indicando que ele era bom em identificar corretamente os 5s que ele classificava, mas falhava em detectar uma parte significativa dos 5s reais.

Explorou-se o trade-off entre precis√£o e revoca√ß√£o, ajustando o limiar de decis√£o do SGDClassifier. Foi demonstrado como escolher um limiar que atenda a um requisito espec√≠fico de precis√£o (por exemplo, 90%) e o impacto disso na revoca√ß√£o.

Por fim, a curva ROC (Receiver Operating Characteristic) e a √Årea sob a Curva (AUC) foram utilizadas para avaliar o desempenho geral do classificador bin√°rio, especialmente em diferenciar as classes positiva e negativa.

## üî¢ Classifica√ß√£o Multiclasse

Expandindo para a classifica√ß√£o de todos os 10 d√≠gitos, foram explorados classificadores multiclasse. Alguns algoritmos (como SGD e RandomForest) lidam com m√∫ltiplas classes nativamente, enquanto outros (como SVMs) s√£o bin√°rios e requerem estrat√©gias como One-vs-Rest (OvR) ou One-vs-One (OvO).

Foi demonstrado o uso de um classificador SVM, que automaticamente utilizou a estrat√©gia OvO no scikit-learn. Tamb√©m foi for√ßado o uso da estrat√©gia OvR com um classificador SVM.

O SGDClassifier tamb√©m foi aplicado √† tarefa multiclasse. A avalia√ß√£o inicial com valida√ß√£o cruzada mostrou uma acur√°cia acima de 85%. A aplica√ß√£o da padroniza√ß√£o dos dados (StandardScaler) resultou em uma melhora not√°vel na acur√°cia do modelo.

## ‚ùå An√°lise de Erro

Para entender melhor onde o modelo multiclasse comete erros, foi analisada a matriz de confus√£o. Uma representa√ß√£o visual da matriz de confus√£o normalizada ajudou a identificar quais classes s√£o mais frequentemente confundidas. Por exemplo, observou-se que muitos d√≠gitos de outras classes foram erroneamente classificados como '8'.

A an√°lise de erros individuais, visualizando exemplos de d√≠gitos classificados incorretamente, forneceu insights sobre as causas dos erros, como a semelhan√ßa visual entre d√≠gitos (por exemplo, 3 e 5) e a sensibilidade do classificador linear a varia√ß√µes na escrita e rota√ß√£o.

## üè∑Ô∏è Classifica√ß√£o Multirr√≥tulo (Extra)

Foi apresentado um exemplo de classifica√ß√£o multirr√≥tulo, onde cada inst√¢ncia pode ter m√∫ltiplos r√≥tulos associados. O exemplo consistiu em classificar os d√≠gitos com base em duas propriedades: ser grande (>= 7) e ser √≠mpar. Foi utilizado um classificador KNeighborsClassifier para esta tarefa e avaliado com o F1-score m√©dio (macro average).

## üì§ Classifica√ß√£o Multioutput (Extra)

Como uma generaliza√ß√£o da classifica√ß√£o multirr√≥tulo, foi demonstrada a classifica√ß√£o multioutput. Um sistema de remo√ß√£o de ru√≠do de imagens foi criado. Ru√≠do aleat√≥rio foi adicionado √†s imagens do dataset, e um KNeighborsClassifier foi treinado para prever a imagem original (sem ru√≠do) a partir da imagem ruidosa. Cada pixel da imagem de sa√≠da √© um r√≥tulo com m√∫ltiplos valores poss√≠veis (intensiade do pixel).

## üíø Como Rodar o C√≥digo

Para executar este projeto, siga os passos abaixo:

1. Clone o reposit√≥rio para sua m√°quina local.
2. Certifique-se de ter as bibliotecas Python necess√°rias instaladas (numpy, matplotlib, scikit-learn). Voc√™ pode instal√°-las usando pip: `pip install numpy matplotlib scikit-learn`.
3. O dataset MNIST ser√° baixado automaticamente pelo scikit-learn na primeira execu√ß√£o.
4. Execute o notebook Python (`.ipynb`) em um ambiente como Jupyter Notebook ou Google Colab.

## ‚úÖ Conclus√£o

Este projeto explorou diversas t√©cnicas de classifica√ß√£o de machine learning aplicadas ao dataset MNIST. Foi poss√≠vel demonstrar a implementa√ß√£o e avalia√ß√£o de classificadores bin√°rios e multiclasse, entender a import√¢ncia de m√©tricas de avalia√ß√£o apropriadas para datasets assim√©tricos, analisar erros para identificar √°reas de melhoria e explorar conceitos mais avan√ßados como classifica√ß√£o multirr√≥tulo e multioutput. O SGDClassifier demonstrou um desempenho razo√°vel, que pode ser melhorado com pr√©-processamento como a padroniza√ß√£o dos dados. A an√°lise de erros destacou a import√¢ncia de considerar as caracter√≠sticas dos dados e do modelo para otimizar o desempenho.
